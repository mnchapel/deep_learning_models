---
title: AlexNet
author: Marie-Neige Chapel
date: 2012-01-01
category: CNN
layout: post
---

Network features:

- 8 layers (5 convolutional + 3 fully connected)
- use ReLu after convolutional layer. This is one of the first neural network to use this activation function. The authors chose ReLu because *"Deep convolutional neural networks with ReLUs train several times faster than their equivalents with tanh units"* [1].

## Architecture

{% include model_architecture.html img_detailed='assets/img/alexnet_detailed.svg' %}

{% include_relative conv_relu.md %}

{% include_relative fc_relu.md %}
**Except for the last fully connected layer!**

## Bibliography

- [1] [[Paper] ImageNet classification with deep convolutional neural networds](https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
